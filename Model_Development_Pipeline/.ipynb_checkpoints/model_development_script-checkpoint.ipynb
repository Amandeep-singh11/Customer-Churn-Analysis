{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "import boto\n",
    "from boto.s3.key import Key\n",
    "from boto.s3.connection import Location\n",
    "import os, sys, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "# df = pd.read_excel('Customer-Churn-Dataset.xls')\n",
    "# X_train, X_test = train_test_split(df, test_size=0.20, random_state=7)\n",
    "# X_train.to_csv('churn_train.csv', index=False)\n",
    "# X_test.to_csv('churn_test.csv', index=False)\n",
    "\n",
    "# Initial Split of Data\n",
    "df = pd.read_csv('churn_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing empty spaces with Null values\n",
    "df = df.replace(r'^\\s+$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping NA values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the 'SeniorCitizen' variable from interger to categorial\n",
    "df['SeniorCitizen']=pd.Categorical(df['SeniorCitizen'])\n",
    "\n",
    "# Change the 'TotalCharges' variable from object to interger \n",
    "df['TotalCharges']=pd.to_numeric(df['TotalCharges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the custumerID column\n",
    "del df[\"customerID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data according to datatypes\n",
    "num = ['float64', 'int64']\n",
    "num_df = df.select_dtypes(include=num)\n",
    "obj_df = df.select_dtypes(exclude=num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'Churn' variable in numeric dataset\n",
    "num_df = pd.concat([num_df,df[\"Churn\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating bins and plotting Countplot for 'tenure'\n",
    "tenure_bins=pd.cut(num_df[\"tenure\"], bins=[0,20,60,80], labels=['low','medium','high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating bins and plotting Countplot for 'MonthlyCharges'\n",
    "MonthlyCharges_bins=pd.cut(num_df[\"MonthlyCharges\"], bins=[0,35,60,130], labels=['low','medium','high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating bins and plotting Countplot for 'MonthlyCharges'\n",
    "TotalCharges_bins=pd.cut(num_df[\"TotalCharges\"], bins=[0,1000,4000,10000], labels=['low','medium','high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving bins into dataframe\n",
    "bins=pd.DataFrame([tenure_bins, MonthlyCharges_bins, TotalCharges_bins]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting SeniorCitizen variable into categorical and mapping values of 1 & 0 to Yes & No respectively\n",
    "df['SeniorCitizen'] = df.SeniorCitizen.map({0:'No', 1:'Yes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate bins with object variables\n",
    "df=pd.concat([bins,obj_df],axis=1)\n",
    "\n",
    "# Convert all the variables into categorical\n",
    "for i in list(df.columns):\n",
    "    df[i] = pd.Categorical(df[i]) \n",
    "dummy = pd.get_dummies(df) # Transform the categorical variables into dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing dataset\n",
    "features = dummy.drop([\"Churn_Yes\", \"Churn_No\"], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dummy[features]\n",
    "y = dummy[\"Churn_Yes\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "[[759  91]\n",
      " [134 141]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.89      0.87       850\n",
      "          1       0.61      0.51      0.56       275\n",
      "\n",
      "avg / total       0.79      0.80      0.79      1125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Logistic Regression Model\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "predictions = logistic_regression.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logistic_regression.pkl', \"wb\") as fp:\n",
    "    pickle.dump(logistic_regression, fp, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID = input\n",
    "AWS_SECRET_ACCESS_KEY = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploadToS3(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, filePath, destinationPath = ''):\n",
    "    \n",
    "    bucket_name = 'ads-final-project' + time.strftime(\"%y%m%d%H%M%S\") + '-dump'\n",
    "    conn = boto.connect_s3(AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY)\n",
    "    bucket = conn.create_bucket(bucket_name,location=boto.s3.connection.Location.DEFAULT)\n",
    "    \n",
    "    print ('Uploading '+filePath+' to Amazon S3 bucket '+bucket_name)\n",
    "    def percent_cb(complete, total):\n",
    "        sys.stdout.write('.')\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    k = Key(bucket)\n",
    "    k.key = destinationPath+\"/\"+filePath\n",
    "    k.set_contents_from_filename(filePath, cb = percent_cb, num_cb = 10)\n",
    "    print('Uploaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading logistic_regression.pkl to Amazon S3 bucket ads-final-project180418165447-dump\n",
      "..Uploaded\n"
     ]
    }
   ],
   "source": [
    "uploadToS3(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, 'logistic_regression.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
